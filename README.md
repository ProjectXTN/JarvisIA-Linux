ğŸ§  Jarvis IA

Jarvis is an intelligent, sarcastic, and futuristic AI assistant inspired by Tony Stark's iconic system.
Built in Python, it features voice interaction, vision models, command automation, emotional memory, music search, autonomous learning, and much more â€” all running locally on your machine.

ğŸ’» Requirements

    Python 3.10

    CUDA-compatible GPU (optional, for faster Whisper)

    Ollama running on Windows Host (for LLaMA 3.3 and LLaMA 3.2 Vision models)

    Ubuntu Virtual Machine (for running Jarvis)

    ffmpeg, git, git-lfs

    Internet connection for web search and autonomous learning

    PulseAudio or ALSA configured for microphone input in VM

ğŸ”¥ Main Features

    ğŸ™ Wake Word Detection â€” Activates on hearing â€œJarvisâ€

    ğŸ§ Voice Activity Detection (VAD) â€” Smart, real-time listening

    ğŸ—£ Text-to-Speech â€” Fast local voice synthesis with Piper (no cloud dependencies)

    ğŸ§ Speech-to-Text â€” High-performance transcription with Whisper (or Whisper.cpp for CPU)

    ğŸ§  Contextual Memory â€” LLaMA 3.3 (for deep answers and continuity)

    ğŸ‘ Vision Model â€” LLaMA 3.2 Vision 90B (for image understanding)

    ğŸ§© Multi-command parsing â€” e.g. â€œOpen the folder and play musicâ€

    ğŸ” Web fallback â€” If uncertain, Jarvis searches autonomously

    ğŸ–¼ Vision from local images â€” Describe images inside imagens/ folder

    ğŸ’¾ Short-term Memory â€” Session context

    ğŸ§  Long-term Persistent Memory â€” Stored in SQLite

    â¤ï¸ Emotional Memory â€” Save happy/sad moments by voice

    ğŸ“˜ Reflective Mode â€” Voice journaling with emotional tagging

    ğŸ§  Autonomous Web Learning â€” Scrapes and stores new knowledge

    ğŸ’» App and System Control â€” Open apps, folders, browser tabs

    ğŸµ Apple Music Integration â€” Search, play, control music via voice

    ğŸ§± Highly Modular Architecture â€” Easy to extend new commands

ğŸ—‚ Project Structure

jarvis/
â”œâ”€â”€ comandos/          # Modular commands (music, system, folders, memory, etc.)
â”œâ”€â”€ brain/             # Audio, memory, utils, dev tools
â”œâ”€â”€ core/              # Model initialization and system integration
â”œâ”€â”€ imagens/           # Local images for vision tasks
â”œâ”€â”€ tests/             # Model testing scripts
â”œâ”€â”€ jarvis.py          # Main executable
â”œâ”€â”€ requirements.txt   # Python dependencies
â””â”€â”€ README.md          # This file

ğŸ—£ï¸ Example Voice Commands

    "Jarvis, open the downloads folder"

    "Jarvis, describe the image skyline"

    "Jarvis, shut down"

    "Jarvis, play Arctic Monkeys"

    "Jarvis, search on the internet what is quantum computing"

    "Jarvis, remember that coding made me happy"

    "Jarvis, what made me happy this month?"

    "Jarvis, let's write today's diary"

ğŸ–¼ï¸ Vision Mode (LLaMA 3.2 Vision 90B)

Trigger advanced image understanding with:

    "Describe the image skyline with details"

    "Give me a detailed description of the image"

(Default: falls back to a faster text-only model when not specifically vision-triggered.)
ğŸµ Apple Music Integration

Jarvis can:

    ğŸ¶ Open your library: "Jarvis, open Apple Music"

    ğŸ” Search and play: "Jarvis, play Arctic Monkeys"

    â¯ Pause, resume, next track: "pause music", "next song"

â¤ï¸ Emotional Memory

    Save emotional events:
    "Jarvis, remember that my birthday made me happy"

    Retrieve memories:
    "Jarvis, what made me happy this month?"

    Reflective voice journaling:
    "Jarvis, I want to record today's diary"

ğŸ§  Autonomous Learning

Jarvis learns dynamically:

    "Jarvis, search what is quantum entanglement and learn it"

It will:

    Scrape trustworthy sources

    Summarize the information

    Save it into the long-term memory database (with timestamp)

ğŸš€ Getting Started

# Clone the repository
git clone https://github.com/ProjectXTN/Jarvis_IA.git

# Navigate to the project
cd Jarvis_IA

# Create the virtual environment
python3.10 -m venv venv-linux

# Activate the environment
source venv-linux/bin/activate

# Install Python dependencies
pip install -r requirements.txt

    Make sure Ollama is running on your Windows host:

ollama serve

    Set the proper OLLAMA_HOST inside your Ubuntu VM if needed:

export OLLAMA_HOST="http://<your_windows_ip>:11500"

(Jarvis detects it automatically if configured.)
ğŸ”’ Lock System

Jarvis uses a .lock file to ensure only one instance runs at a time.
ğŸ§˜ Voice Deactivation

You can stop active interaction by saying:

    "Jarvis, stop responding"

    "Jarvis, silence"

    "Jarvis, mute"

Jarvis will return to passive wake-word listening.
ğŸ“ˆ Performance Tips

    Increase VM CPU cores and RAM for better real-time performance.

    Piper TTS is up to 10x faster than cloud TTS systems.

âœ¨ Made with ğŸ’¥ by Pedro